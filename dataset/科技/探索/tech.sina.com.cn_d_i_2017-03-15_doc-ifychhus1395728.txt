　　新浪科技讯 北京时间3月15日消息，据国外媒体报道，斯蒂芬·霍金近日警告称，技术的发展需要得到控制，以阻止其毁灭人类。在此之前，这位世界知名的物理学家就曾警告过人工智能的危险。他认为，人类必须找到一种方法，在重大破坏造成之前迅速发现所面临的威胁。　　“从文明开始之时，侵略就一直是很有用处，因为它有着绝对的生存优势，”霍金说，“通过达尔文式的演化过程，侵略性深深根植于我们的基因之中。然而，如今的技术发展已经加快到了某种程度，使这种侵略性可能会以核战争或生物战争的形式毁灭人类。我们需要用逻辑和理性来控制这种与生俱来的本能。”　　不过，霍金也表示，尽管人类面临着各种各样的问题，但依然有希望存活下去，而这需要我们所有人都一起努力。“我们需要更快地认识这些威胁，并在它们失去控制之前采取行动。这可能意味着需要建立某种形式的世界政府，”霍金说道。　　世界政府可能也会产生各种各样的问题。“（世界政府）可能会变成一种暴政，”霍金说，“所有这些听起来似乎是在说人类已经在劫难逃，但我是一个乐观主义者。我认为人类将奋起应对这些挑战。”　　在2015年的一次网络问答中，霍金指出人工智能可能会成长到非常强大的程度，甚至可能在完全无意的情况下毁灭人类。“人工智能的真正威胁并不在于它们的恶意，而是它们所具有的能力，”霍金说，“一个超级聪明的人工智能在完成目标时具有极强的能力，而一旦这些目标与我们人类不一致，那我们就有麻烦了。”　　他继续说道：“你可能并不是一个讨厌蚂蚁的人，但也会无意中踩死蚂蚁，而如果你负责一个水力发电的绿色能源项目，项目所在的区域内也可能会有许多蚂蚁巢穴被水淹没，对蚂蚁来说就非常不幸。我们要避免人类处于这些蚂蚁的境地。”　　公司的首席执行官也提出了类似的观点，他曾警告称，人工智能的发展必须受到控制。“随着时间推移，我认为我们可能会看到生物智能和数字智能出现更加密切的融合，”马斯克说道。他还提出，人类在未来可能会与机器实现结合，以跟上人工智能的发展步伐。（任天）